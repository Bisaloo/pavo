---
title: "An introduction to pavo 1.0"
author: "Rafael Maia, Pierre-Paul Bitton, Chad Eliason, Thomas White"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
bibliography: refs.bib
vignette: >
  %\VignetteIndexEntry{An introduction to pavo 1.0}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r, echo=FALSE, warning=FALSE, results='hide', message=FALSE}
library(pavo)
```

# Introduction

`pavo` is an `R` package that was developed with the goal of establishing a flexible and integrated workflow for working with spectral color data. It includes functions that take advantage of new data classes to work seamlessly from importing raw data to visualization and analysis. Here we are excited to introduce the stable release of `pavo 1.0`, which---among other things---includes a suite of new analysis and visualisation tools to make working with colour data simpler and more intuitive than ever. 

`pavo` was written with the following workflow in mind, which remains true with this release:

1. **Organize** spectral data by inputting files and processing spectra (e.g., to remove noise, negative values, smooth curves, etc...).
2. **Analyze** the resulting files, either using typical colorimetric variables (hue, saturation, brightness) or using visual models based on perceptual data from the taxon of interest.
3. **Visualize** the output, with multiple options provided for exploratory analyses.

While we have made various improvements that will expedite data organisation, the most significant developments in `1.0` pertain to the analysis and visualisation of colour data. This includes greater flexibility in the initial visual modelling process, and a host of new colorspace models and associated plotting options which are accessable through a simplified workflow. Below we will explore the main new features introduced in `1.0` in an example workflow. 

# Data

`pavo 1.0` includes a new example dataset consisting of tidy reflectance spectra from 36 Australian angiosperm species. It can be accessed using `data(flowers)`, and we'll use it to illustrate many of the new features.   
```{r}
data(flowers)

head(flowers[1:4])
```

# Visual modelling

## Visual Phenotypes

`pavo` is now equipped with several new di-, tri- and tetrachromatic visual systems, to accompany the suite of new models. The full complement of included systems are accessable via the `vismodel()` option `visual`, and include:
  : `avg.uv` average ultraviolet-sensitive avian (tetrachromat)
  : `avg.v` average violet-sensitive avian (tetrachromat)
  : `bluetit` The blue tit _Cyanistes caeruleus_ (tetrachromat)
  : `star` The starling _Sturnus vulgaris_ (tetrachromat)
  : `pfowl` The peafowl _Pavo cristatus_ (tetrachromat)
  : `apis` The honeybee _Apis mellifera_ (trichromat)
  : `canis` The canid _Canis familiaris_ (dichromat)
  : `musca` The housefly _Musca domestica_ (tetrachromat)
  : `cie2` 2-degree colour matching functions for CIE models of human colour vision (trichromat)
  : `cie10` 10-degree colour matching functions for CIE models of human colour vision (trichromat)

As in previous versions, the individual sensitivity functions can be accessed via a call to `vissyst`, and examined using pavo's `plot` function. 

```{r fig=TRUE, include=TRUE, warnings=FALSE, message=FALSE, echo=FALSE, fig.width=8, fig.height=28, fig.align='center', fig.cap="_The visual phenotypes included in pavo 1.0._"}
par(mfrow = c(10, 2))
plot(as.rspec(cbind(vissyst$wl, vissyst[2:5])), main = 'Average avian UV', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[14:17])), main = 'Average avian V', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[6:9], vissyst$bt.dc)), main = 'Blue tit', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[10:13], vissyst$st.dc)), main = 'Starling', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[18:21], vissyst$ch.dc)), main = 'Peafowl', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[25:27])), main = 'Honeybee', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[28:29])), main = 'Canis familiaris', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[30:32])), main = 'CIE 2-degree', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[33:35])), main = 'CIE 10-degree', ylab = 'Absorbance')
plot(as.rspec(cbind(vissyst$wl, vissyst[36:39], vissyst$md.r1)), main = 'Musca domestica', ylab = 'Absorbance')
```

## The `vismodel` Function and Receptor-noise Limited Model

...new tweaks to vismodel & receptor noise (raf?)...

...`vismodel` also now includes the option of hyperbolically transforming quantum catches by specifying `qcatch = 'Ei'`:

$$E_i = \frac{Q_i}{Q_i + 1}$$

Where E~i~ is the 'excitation value` for photoreceptor _i_, and Q~i~ is the raw quantum catch of said photoreceptor. The transformation is a simplification of the Michaelisâ€“Menton photoreceptor equation [@dowling1987retina; @backhaus1987color], and is particularly common in models of Hymenopteran vision [@backhaus1987color; @chittka1992colour; @backhaus1991color].  

## Modelling and Plotting Colourspaces

### The `colspace` and `plot` Functions

The most significant structural changes in `1.0` involve the workflow for visual modelling, particular as regards the use of colorspaces. Previously, for example, we might use `vismodel` to model photoreceptor stimulation to an avian viewer, `tcs` to convert the data to points in a tetrahedral colorspace, and `tcsplot` to visualise the data. In `1.0` these, and all other, colorspace modelling and plotting options are now wrapped into the new `colspace`  and `plot` functions. For modelling in colorspace, a typical workflow might use:  

1. `vismodel` to estimate photoreceptor quantum catches. The assumptions of many colorspace models may differ dramatically, so be sure to select options that are appropriate for your intended use.   
2. `colspace` to convert the results of `vismodel` (or user-provided quantum catches) into points in a given colorspace, specified with the `space` argument. If no `space` argument is provided, `colspace` will automatically select the di-, tri- or tetrahedral colorspace, depending on the nature of the inpput data. The result of `colspace` will be an object of class `colspace` (that inherits from `data.frame`; see the 'Under-the-hood' section below), and will contain the location of stimuli in the selected space along with any associated color variables. 
3. `plot` the output. `plot` will automatically select the appropriate visualisation based on the input `colspace` object, and will also accept various graphical parameters depending on the colorspace (see `?plot.colspace` for details) . 

### Di-, Tri-, and Tetrachromatic Spaces

While `pavo` has always included the ability to model spectra in a tetrahedral colourspace, `1.0` now expands this ability to di- and trichromatic spaces, and (as outlined above) unites these approaches in a cohesive workflow. As with most colorspace models, we first estimate relative quantum catches with various assumptions by using the `vismodel` function, before converting each set of values to a location in colorspace by using the `space` argument in `colspace`. For di- tri- and tetrechromatic spaces, `colspace` calculates the coordinates of stimuli as:
  : Dichromats:
    : $$x = \frac{1}{\sqrt{2}}(Q_l - Q_s)$$
  : Trichromats:
    : $$x = \frac{1}{\sqrt{2}}(Q_l - Q_m)$$
    : $$y = \frac{\sqrt{2}}{\sqrt{3}}(Q_s - \frac{Q_l + Q_m}{2})$$
  : Tetrachromats:
    : $$x = \frac{1}{\sqrt{2}}(Q_l - Q_m)$$
    : $$y = \frac{\sqrt{2}}{\sqrt{3}}(Q_s - \frac{Q_l + Q_m}{2})$$
    : $$z = \frac{\sqrt{3}}{2}(Q_u - \frac{Q_l + Q_m + Q_s}{3})$$

Where Q~u~, Q~s~, Q~m~, and Q~l refer to quantum catch estimates for UV-, short, medium-, and long-wavelength photoreceptors.

For a dichromatic example, we can model our floral reflectance data using the visual system of the domestic dog _Canis familiaris_, which has two cones with maximal sensitivity near 440 and 560 nm.   

```{r}
vis.flowers <- vismodel(flowers, visual = 'canis')

di.flowers <- colspace(vis.flowers, space = 'di')

head(di.flowers)
```

The output contains values for the relative stimulation of shot- and long-wavelength sensitive photoreceptors associated with each flower, along with its single coordinate in dichromatic space and its r.vector (distance from the origin). To visualise where these points lie, we can simply plot them on a segment.

```{r, fig=TRUE, include=TRUE, fig.width=5, fig.height=5, fig.align='center', fig.cap="_Flowers in a dichromatic colorspace, as modelled according to a canid visual system._"}
plot(di.flowers) 
```

For our trichromatic viewer we can use the honeybee _Apis melifera_, one of the most significant and widespread pollinators. We'll also transform our quantum catches according to Fechner's law by specifying `qcatch = 'fi'`, and will model photoreceptor stimulation under bright conditions by scaling our illuminant with the `scale` argument. 

```{r}
vis.flowers <- vismodel(flowers, visual = 'apis', qcatch = 'fi', scale = 10000)

tri.flowers <- colspace(vis.flowers, space = 'tri')

head(tri.flowers)
```

As in the case of our dichromat, the output contains relative photoreceptor stimulations, coordinates in the Maxwell triangle, a well as the 'hue angle' `h.theta` and distance from the origin (`r.vec`).  

```{r, fig=TRUE, include=TRUE, fig.width=6, fig.height=6, fig.align='center', fig.cap="_Floral reflectance in a Maxwell triangle, considering a honeybee visual system._"}
plot(tri.flowers) 
```

Finally, we'll draw on the blue tit's visual system to model our floral reflectance spectra in a tetrahedral space, again using log-transformed quantum catches and assuming bright viewing conditions. 

```{r}
vis.flowers <- vismodel(flowers, visual = 'bluetit', qcatch = 'fi', scale = 10000)

tetra.flowers <- colspace(vis.flowers, space = 'tcs')

head(tetra.flowers)
```

As in previous versions of `pavo`, tetrahedral data (now via `colspace(space = 'tcs')`) may be visualised in an _interactive_ plot by using `tcsplot`, along with the accessory functions `tcspoints` and `tcsvol` for adding points and convex hulls, respectively. Version `1.0`, however, now also includes a _static_ tetrahedral plot, based on functionality from the package `scatterplot3d`. As with other colorspace plots there are a number of associated graphical options, though the `view` option is particularly useful, as it controls the orientation of the tetrahedron by specifying a viewing angle from 0 to 360 (in degrees).

```{r, fig=TRUE, include=TRUE, fig.width=7.2, fig.height=5, fig.align='center', fig.cap="_Flowers in a tetrahedral colorspace, with varied orientations, modelled using the visual phenotype of the blue tit._"}
par(mfrow = c(1, 2))
plot(tetra.flowers, view = 100) 
plot(tetra.flowers, view = 75)
```

### The Color Hexagon

The hexagon colour space of Chittka [-@chittka1992colour] is a model of hymenopteran vision that has found extremely broad use, particularly in studies of bee-flower interactions. It's also often broadly applied across hymenopteran species, because the photopigments underlying trichromatic vision in Hymenoptera appear to be quite conserved [@briscoe2001evolution]. What's particularly useful is that color distances within the hexagon have been extensively validated against behaviour, and thus offer a relatively reliable measure of perceptual distance [e.g. @dyer2008comparative; @avargues2010aversive; @chittka1992colour].

We then converted photoreceptor stimulation values to neural excitations using the hyperbolic transform

Coordinates:

$$x = \frac{\sqrt{3}}{2(E_g = E_{uv})}$$

$$y = E_b - 0.5(E_{uv} + E_g)$$

```{r}
vis.flowers <- vismodel(flowers, visual = 'apis', qcatch = 'Ei', relative = FALSE, vonkries = TRUE, achro = 'l', bkg = 'green')

hex.flowers <- colspace(vis.flowers, space = 'hexagon')

head(hex.flowers)
```

```{r, fig=TRUE, include=TRUE, fig.width=6, fig.height=6, fig.align='center', fig.cap="_Colour hexagon._"}
plot(hex.flowers, sectors = 'coarse')
```

### The Colour Opponent Coding (COC) Space

ref [@backhaus1991color]

$$A = -9.86E_g + 7.70E_b + 2.16E_g$$
$$B = -5.17E_g + 20.25E_b - 15.08E_g$$

```{r}
vis.flowers <- vismodel(flowers, visual = 'apis', qcatch = 'Ei', relative = FALSE, vonkries = TRUE)

coc.flowers <- colspace(vis.flowers, space = 'coc')

head(coc.flowers)

```

```{r, fig=TRUE, include=TRUE, fig.width=6, fig.height=6, fig.align='center', fig.cap="_coc._"}
plot(coc.flowers) 
```

### CIE Spaces

XYZ Tristimulus values:

$$X = k\int_{300}^{700}{R(\lambda)I(\lambda)\bar{x}(\lambda)d\lambda}$$
$$Y = k\int_{300}^{700}{R(\lambda)I(\lambda)\bar{y}(\lambda)d\lambda}$$
$$Z = k\int_{300}^{700}{R(\lambda)I(\lambda)\bar{z}(\lambda)d\lambda}$$

where k is a normalising factor:

$$k = \frac{100}{\int_{300}^{700}{I(\lambda)\bar{y}(\lambda)d\lambda}}$$

Chromaticity coordinates:

$$x = \frac{X}{X + Y + Z}$$
$$y = \frac{Y}{X + Y + Z}$$
$$z = \frac{Z}{X + Y + Z} = 1 - x - y$$

LAB:
$$L = 116\left(\frac{Y}{Y_n}\right)^\frac{1}{3} \;\; if \;\; \frac{Y}{Y_n} > 0.008856$$
$$L = 903.3\left(\frac{Y}{Y_n}\right) \;\; if \;\; \frac{Y}{Y_n} \leq 0.008856$$

$$a = 500\left(f\left(\frac{X}{X_n}\right) - f\left(\frac{Y}{Y_n}\right)\right)$$

$$b = 500\left(f\left(\frac{Y}{Y_n}\right) - f\left(\frac{Z}{Z_n}\right)\right)$$

where:

$$f(x) = x^\frac{1}{3} \;\; if \;\; x > 0.008856$$
$$f(x) = 7.787(x) + \frac{16}{116} \;\; if \;\; x \leq 0.008856$$

Here, $X_n, Y_n, Z_n$ are neutral point values to model visual adaptation, calculated as:

$$X_n = \int_{300}^{700}{R_n(\lambda)I(\lambda)\bar{x}(\lambda)d\lambda}$$
$$Y_n = \int_{300}^{700}{R_n(\lambda)I(\lambda)\bar{y}(\lambda)d\lambda}$$
$$Z_n = \int_{300}^{700}{R_n(\lambda)I(\lambda)\bar{z}(\lambda)d\lambda}$$

when $R_n(\lambda)$ is a perfect diffuse reflector (i.e. 1).


```{r}
vis.flowers <- vismodel(flowers, visual = 'cie2', illum = 'D65')

ciexyz.flowers <- colspace(vis.flowers, space = 'ciexyz')
cielab.flowers <- colspace(vis.flowers, space = 'cielab')

head(ciexyz.flowers)

head(cielab.flowers)
```

```{r, fig=TRUE, include=TRUE, fig.width=6, fig.height=6, fig.align='center', fig.cap="_CIEXYZ._"}
plot(ciexyz.flowers) 
```

```{r, fig=TRUE, include=TRUE, fig.width=6, fig.height=6, fig.align='center', fig.cap="_CIELAB._"}
plot(cielab.flowers) 
```

### Categorical Fly Colourspace

First, we used the categorical colour vision model of Troje [@troje1993spectral]. This model assumes the involvement of all four photoreceptor classes , and further posits that colour vision is based on two specific opponent mechanisms (R7p - R8p, and R7y - R8y). Based on behavioural data from _Lucilia_ sp.  the model predicts that colours are perceptually grouped into one of four colour categories, and that flies are unable to distinguish between colours that fall within the same category.

We then calculated the difference in relative stimulation between the 'pale' (R7p - R8p) and 'yellow' (R7y - R8y) photoreceptor pairs. The signs of these differences together define the four possible fly-colour categories [p+y+, p-y+, p+y-, p-y-].        


$$x = R7_p - R8_p$$

$$y = R7_y - R8_y$$

```{r}
vis.flowers <- vismodel(flowers, qcatch = 'Qi', visual = 'musca', achro = 'none', relative = TRUE)

cat.flowers <- colspace(vis.flowers, space = 'categorical')

head(cat.flowers)
```

```{r, fig=TRUE, include=TRUE, fig.width=6, fig.height=6, fig.align='center', fig.cap="_Cat._"}
plot(cat.flowers) 
```

# N-dimensional colour-distances with `coldist`

# Under-the-Hood

## Classes

## Attributes

# Help

- bug reports, gitter etc.

# References


